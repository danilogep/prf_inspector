"""
Servi√ßo de An√°lise Forense com IA v5.33
=======================================
CORRE√á√ÉO CR√çTICA - ULTRA CONSERVADOR

PROBLEMA CORRIGIDO (v5.33):
- IA estava gerando FALSOS POSITIVOS em massa (97% de erro)
- Causas:
  1. IA classificando varia√ß√µes normais de caracteres como "erro"
  2. IA confundindo textura normal de motor usado com "marcas de lixa"
  3. Score calculado baseado em an√°lise detalhada de caracteres

SOLU√á√ÉO (v5.33):
- Prompt ultra-simplificado: ignora formato de caracteres
- C√°lculo de score ignora "marcas de lixa" (IA erra muito)
- √öNICAS evid√™ncias que aumentam score:
  * N√∫meros fantasma (vest√≠gios de numera√ß√£o anterior)
  * Mistura laser/estampagem na mesma numera√ß√£o
- Tudo mais = ASSUME ORIGINAL

TAXA ESPERADA: ~95% acertos em ORIGINAIS

CORRE√á√ïES DE BUGS (v5.16):
1. Race condition no upload de imagem (adicionado lock)
2. Memory leak no OpenCV (adicionado cleanup expl√≠cito)
3. JSON parsing mais robusto
4. Timeout handling melhorado
5. Valida√ß√£o de input em todos os m√©todos p√∫blicos

L√ìGICA DE SCORE v5.33 (ULTRA CONSERVADOR):
- Base: 15 (assume ORIGINAL)
- N√∫meros fantasma detectados = 95
- Mistura laser/estampagem = 90
- Veredicto ADULTERADO com evid√™ncia f√≠sica = 85
- Veredicto ADULTERADO sem evid√™ncia f√≠sica = 35 (IGNORADO)
- Marcas de lixa = IGNORADO (IA erra muito)
- Diferen√ßas de caracteres = IGNORADO
"""

import base64
import re
import json
import httpx
import time
import io
import threading
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from contextlib import contextmanager

from app.core.logger import logger
from app.core.config import settings

# =====================================================
# MARCADOR v5.33 - ESTE PRINT CONFIRMA ARQUIVO CORRETO
# =====================================================
print("=" * 60)
print("üî∑ FORENSIC_AI_SERVICE v5.33 ULTRA CONSERVADOR CARREGADO!")
print("üî∑ Se voc√™ est√° vendo isto, o arquivo foi substitu√≠do!")
print("=" * 60)

# OpenCV para filtro forense
try:
    import cv2
    import numpy as np
    OPENCV_AVAILABLE = True
    logger.info("‚úì OpenCV dispon√≠vel para an√°lise forense")
except ImportError:
    OPENCV_AVAILABLE = False
    cv2 = None
    np = None
    logger.warning("‚ö†Ô∏è OpenCV n√£o instalado - pip install opencv-python")


class ForensicAIService:
    """
    An√°lise forense v5.33 - Vers√£o refatorada com corre√ß√µes de bugs e melhorias.
    
    Thread-safe, com cache e valida√ß√£o robusta.
    """
    
    LASER_TRANSITION_YEAR: int = 2010
    API_TIMEOUT: int = 180  # segundos
    MAX_IMAGE_SIZE: int = 10 * 1024 * 1024  # 10MB
    CACHE_TTL: int = 3600  # 1 hora
    
    # N√∫meros cr√≠ticos que fraudadores mais erram
    HIGH_RISK_CHARS: frozenset = frozenset(['0', '1', '3', '4', '5', '6', '8', '9'])
    
    # Prefixos conhecidos - EXPANDIDO
    KNOWN_PREFIXES: Dict[str, Tuple[str, int]] = {
        # CG Series
        'JC9RE': ('CG 160', 160), 'JC96E': ('CG 160', 160),
        'JC30E': ('CG 125i', 125), 'JC30E7': ('CG 125i', 125),
        'MC27E': ('CG 160', 160), 'MC41E': ('CG 150', 150),
        'MC44E': ('CG 150', 150), 'MC44E1': ('CG 150', 150),
        
        # XRE Series
        'ND09E1': ('XRE 300', 300), 'ND11E1': ('XRE 300', 300),
        'MD09E': ('XRE 300', 300), 'MD09E1': ('XRE 300', 300),
        
        # CB Series
        'NC51E': ('CB 500F/X/R', 500), 'NC49E': ('CB 500', 500),
        'NC49E1': ('CB 500', 500), 'NC49E1F': ('CB 500F', 500),
        'NC61E': ('CB 650', 650), 'NC61E0': ('CB 650R', 650),
        
        # Bros
        'MD41E': ('NXR 160 Bros', 160), 'MD41E0': ('NXR 160 Bros', 160),
        
        # S√©rie KC/KD (antigos/exporta√ß√£o)
        'KC08E1': ('CG 125', 125), 'KC08E2': ('CG 125', 125),
        'KC22E1': ('CG 125', 125),
        'KD03E3': ('Motor Gen√©rico', 0),
        'KD08E1': ('Sahara/XLR 125', 125), 'KD08E2': ('Sahara/XLR 125', 125),
        'KF34E1': ('Titan 150', 150),
    }
    
    def __init__(self):
        """Inicializa o servi√ßo com configura√ß√µes e valida√ß√µes."""
        self._lock = threading.Lock()
        self._cache: Dict[str, Tuple[Dict, float]] = {}
        
        # Configura√ß√£o da API
        self.api_key = getattr(settings, 'ANTHROPIC_API_KEY', None)
        self.enabled = bool(self.api_key and len(self.api_key) > 20)
        
        # Supabase
        self.supabase = self._init_supabase()
        
        # URLs de fontes para refer√™ncia
        self.font_urls = self._load_font_urls()
        
        # Cache de imagens em base64 (carrega uma vez)
        self.font_cache_b64 = self._preload_font_cache()
        
        if self.enabled:
            logger.info(f"‚úì ForensicAIService v5.33 inicializado")
            logger.info(f"  API Key: {self.api_key[:20]}..." if self.api_key else "  API Key: N√£o configurada")
        else:
            logger.warning("‚ö†Ô∏è ForensicAIService desabilitado - ANTHROPIC_API_KEY n√£o configurada")
    
    def _init_supabase(self) -> Optional[Any]:
        """Inicializa conex√£o com Supabase de forma segura."""
        try:
            supabase_url = getattr(settings, 'SUPABASE_URL', None)
            supabase_key = getattr(settings, 'SUPABASE_KEY', None)
            
            if supabase_url and supabase_key:
                from supabase import create_client
                client = create_client(supabase_url, supabase_key)
                logger.info("‚úì Supabase conectado")
                return client
        except ImportError:
            logger.warning("‚ö†Ô∏è Biblioteca supabase n√£o instalada")
        except Exception as e:
            logger.error(f"Erro ao conectar Supabase: {e}")
        
        return None
    
    def _load_font_urls(self) -> Dict[str, str]:
        """
        Carrega URLs das fontes de refer√™ncia Honda.
        
        SIMPLIFICADO v5.33: Usa APENAS fontes gen√©ricas de alta qualidade.
        Formato: "A.png", "0.png", "1.png", etc.
        
        Retorna:
        {
            '0': 'path/to/0.png',
            '1': 'path/to/1.png',
            'A': 'path/to/A.png',
            ...
        }
        """
        font_data = {}
        
        def parse_filename(filename: str) -> Optional[str]:
            """
            Parse nome do arquivo.
            Aceita APENAS formato gen√©rico: "A.png", "0.png"
            Ignora arquivos com _LASER ou _ESTAMPAGEM.
            """
            stem = filename.replace('.png', '').replace('.PNG', '')
            
            # Ignorar arquivos com sufixo _LASER ou _ESTAMPAGEM
            if '_' in stem:
                return None
            
            # Aceitar apenas caracteres √∫nicos
            char = stem.upper()
            if len(char) == 1 and char.isalnum():
                return char
            
            return None
        
        # Tenta carregar do Supabase Storage
        supabase_url = getattr(settings, 'SUPABASE_URL', None)
        supabase_key = getattr(settings, 'SUPABASE_KEY', None)
        
        if supabase_url and supabase_key:
            try:
                base = supabase_url.rstrip('/')
                resp = httpx.post(
                    f"{base}/storage/v1/object/list/honda-fonts",
                    headers={
                        "apikey": supabase_key,
                        "Authorization": f"Bearer {supabase_key}"
                    },
                    json={"prefix": "", "limit": 100},
                    timeout=15.0
                )
                
                if resp.status_code == 200:
                    for item in resp.json():
                        name = item.get('name', '')
                        if name.lower().endswith('.png'):
                            char = parse_filename(name)
                            if char:
                                font_data[char] = f"{base}/storage/v1/object/public/honda-fonts/{name}"
                    
                    if font_data:
                        logger.info(f"‚úì Fontes Supabase: {len(font_data)} caracteres")
                        return font_data
            except Exception as e:
                logger.warning(f"Erro fontes Supabase: {e}")
        
        # Fallback: carregar fontes locais
        try:
            fonts_dir = getattr(settings, 'FONTS_DIR', None)
            
            # Se n√£o configurado, tenta caminhos padr√£o
            if not fonts_dir or not Path(fonts_dir).exists():
                possible_paths = [
                    Path(__file__).parent.parent / 'data' / 'honda_fonts',
                    Path(__file__).parent / 'data' / 'honda_fonts',
                    Path('data/honda_fonts'),
                    Path('backend/data/honda_fonts'),
                ]
                for p in possible_paths:
                    if p.exists():
                        fonts_dir = str(p)
                        break
            
            if fonts_dir and Path(fonts_dir).exists():
                for f in Path(fonts_dir).glob("*.png"):
                    char = parse_filename(f.name)
                    if char:
                        font_data[char] = str(f)
                
                if font_data:
                    logger.info(f"‚úì Fontes locais: {len(font_data)} caracteres")
        except Exception as e:
            logger.warning(f"Erro fontes locais: {e}")
        
        return font_data
    
    def _preload_font_cache(self) -> Dict[str, str]:
        """
        Pr√©-carrega todas as fontes em base64 durante inicializa√ß√£o.
        Isso evita carregar a cada an√°lise, economizando tempo.
        """
        cache = {}
        
        # Carregar apenas N√öMEROS (0-9) - s√£o os mais cr√≠ticos para fraude
        # Letras raramente s√£o alteradas
        numeros = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
        
        for char in numeros:
            if char in self.font_urls:
                b64 = self._load_font_image_base64(self.font_urls[char])
                if b64:
                    cache[char] = b64
        
        if cache:
            logger.info(f"  üì¶ Cache de fontes: {list(cache.keys())}")
        
        return cache
    
    def _load_font_image_base64(self, path_or_url: str) -> Optional[str]:
        """Carrega uma imagem de fonte e retorna em base64."""
        try:
            if path_or_url.startswith('http'):
                resp = httpx.get(path_or_url, timeout=10.0)
                if resp.status_code == 200:
                    return base64.b64encode(resp.content).decode('utf-8')
            else:
                path = Path(path_or_url)
                if path.exists():
                    return base64.b64encode(path.read_bytes()).decode('utf-8')
        except Exception as e:
            logger.warning(f"Erro carregando fonte {path_or_url}: {e}")
        return None
    
    def _get_reference_fonts_for_code(self, code: str) -> Dict[str, str]:
        """
        Obt√©m as fontes de refer√™ncia para os caracteres presentes no c√≥digo.
        
        SIMPLIFICADO v5.33: Usa apenas fontes gen√©ricas de alta qualidade.
        
        Args:
            code: C√≥digo do motor (ex: "MC27E1-A123456")
            
        Returns:
            Dict mapeando caractere -> base64 da imagem de refer√™ncia
        """
        # Extrair caracteres √∫nicos do c√≥digo
        chars_unicos = set()
        for c in code.upper():
            if c.isalnum():
                chars_unicos.add(c)
        
        # Carregar imagens de refer√™ncia
        referencias = {}
        for char in chars_unicos:
            if char in self.font_urls:
                path_or_url = self.font_urls[char]
                b64 = self._load_font_image_base64(path_or_url)
                if b64:
                    referencias[char] = b64
        
        return referencias
    
    @contextmanager
    def _image_buffer(self, image_bytes: bytes):
        """
        Context manager para processamento seguro de imagem.
        Garante cleanup de mem√≥ria do OpenCV.
        """
        np_arr = None
        img = None
        try:
            if OPENCV_AVAILABLE and np is not None:
                np_arr = np.frombuffer(image_bytes, np.uint8)
                img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            yield img
        finally:
            # Cleanup expl√≠cito
            if img is not None:
                del img
            if np_arr is not None:
                del np_arr
    
    def _validate_image(self, image_bytes: bytes) -> Tuple[bool, str]:
        """
        Valida a imagem de entrada.
        
        Returns:
            Tupla (v√°lido, mensagem_erro)
        """
        if not image_bytes:
            return False, "Imagem vazia"
        
        if len(image_bytes) > self.MAX_IMAGE_SIZE:
            return False, f"Imagem muito grande: {len(image_bytes)} bytes (m√°x: {self.MAX_IMAGE_SIZE})"
        
        # Verifica magic bytes
        if image_bytes[:2] == b'\xff\xd8':
            return True, "JPEG"
        elif image_bytes[:8] == b'\x89PNG\r\n\x1a\n':
            return True, "PNG"
        elif image_bytes[:4] == b'RIFF' and image_bytes[8:12] == b'WEBP':
            return True, "WEBP"
        else:
            return False, "Formato de imagem n√£o suportado (use JPEG, PNG ou WEBP)"
    
    def _get_cache_key(self, image_bytes: bytes, year: int) -> str:
        """Gera chave de cache baseada no hash da imagem."""
        image_hash = hashlib.md5(image_bytes).hexdigest()
        return f"{image_hash}_{year}"
    
    def _get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """Retorna resultado em cache se v√°lido."""
        with self._lock:
            if cache_key in self._cache:
                result, timestamp = self._cache[cache_key]
                if time.time() - timestamp < self.CACHE_TTL:
                    logger.info(f"  Cache hit: {cache_key[:16]}...")
                    return result.copy()
                else:
                    del self._cache[cache_key]
        return None
    
    def _set_cache(self, cache_key: str, result: Dict):
        """Armazena resultado em cache."""
        with self._lock:
            # Limita tamanho do cache
            if len(self._cache) > 100:
                # Remove entradas mais antigas
                oldest_keys = sorted(
                    self._cache.keys(),
                    key=lambda k: self._cache[k][1]
                )[:20]
                for key in oldest_keys:
                    del self._cache[key]
            
            self._cache[cache_key] = (result.copy(), time.time())
    
    def get_expected_type(self, year: int) -> str:
        """Retorna tipo de grava√ß√£o esperado para o ano."""
        if not isinstance(year, int) or year < 1970 or year > 2100:
            return "DESCONHECIDO"
        return 'LASER' if year >= self.LASER_TRANSITION_YEAR else 'ESTAMPAGEM'
    
    def get_verdict(self, score: int) -> str:
        """
        Converte score de risco em veredicto textual.
        
        RECALIBRADO v5.16:
        - Limites ajustados para reduzir falsos positivos
        """
        if not isinstance(score, (int, float)):
            return "ERRO"
        
        score = int(score)
        
        if score >= 85:
            return "FRAUDE CONFIRMADA"
        elif score >= 70:
            return "ALTA SUSPEITA"
        elif score >= 50:
            return "SUSPEITO"
        elif score >= 30:
            return "ATEN√á√ÉO"
        elif score >= 15:
            return "VERIFICAR"
        return "REGULAR"
    
    def get_stats(self) -> Dict:
        """Retorna estat√≠sticas do servi√ßo."""
        stats = {
            'enabled': self.enabled,
            'supabase_connected': self.supabase is not None,
            'fonts_loaded': len(self.font_urls),
            'cache_size': len(self._cache),
            'originals': 0,
            'frauds': 0,
            'accuracy_rate': 'N/A'
        }
        
        if self.supabase:
            try:
                response = self.supabase.table('motors_original').select('id', count='exact').execute()
                stats['originals'] = response.count or 0
                
                response = self.supabase.table('motors_fraud').select('id', count='exact').execute()
                stats['frauds'] = response.count or 0
            except Exception as e:
                logger.warning(f"Erro ao obter estat√≠sticas: {e}")
        
        return stats
    
    def analyze(self, image_bytes: bytes, year: int, model: Optional[str] = None) -> Dict:
        """
        M√©todo principal de an√°lise.
        
        Args:
            image_bytes: Imagem do motor em bytes
            year: Ano do ve√≠culo
            model: Modelo opcional para valida√ß√£o cruzada
            
        Returns:
            Dict com resultado completo da an√°lise
        """
        start_time = time.time()
        
        # Estrutura de resultado padr√£o
        result = self._create_empty_result(year)
        
        # Valida√ß√£o de input
        valid, msg = self._validate_image(image_bytes)
        if not valid:
            result['risk_factors'].append(f"‚ö†Ô∏è {msg}")
            result['risk_score'] = 50
            return result
        
        if not isinstance(year, int) or year < 1970 or year > 2100:
            result['risk_factors'].append(f"‚ö†Ô∏è Ano inv√°lido: {year}")
            result['risk_score'] = 50
            return result
        
        # Verifica cache
        cache_key = self._get_cache_key(image_bytes, year)
        cached = self._get_cached_result(cache_key)
        if cached:
            return cached
        
        # Verifica se servi√ßo est√° habilitado
        if not self.enabled:
            result['risk_factors'].append("‚ö†Ô∏è IA n√£o configurada - an√°lise limitada")
            result['risk_score'] = 50
            return result
        
        try:
            logger.info(f"ü§ñ An√°lise v5.33 | Ano: {year} | Tipo esperado: {result['expected_type']}")
            
            # Aplica filtro forense CLAHE
            enhanced_bytes = self._apply_forensic_filter(image_bytes)
            if enhanced_bytes:
                logger.info("  ‚úì Filtro CLAHE aplicado")
            
            # Upload da imagem para an√°lise posterior
            image_url = self._upload_analysis_image(image_bytes)
            
            # Conta refer√™ncias de fontes dispon√≠veis
            result['references_used'] = {
                'fonts': len(self.font_urls)
            }
            
            # An√°lise com IA
            ai_response = self._analyze_with_ai_forensic(
                image_bytes,
                enhanced_bytes,
                year
            )
            
            if ai_response:
                logger.info(f"üîç Resposta AI recebida")
            
            if not ai_response or not ai_response.get('success'):
                error_msg = ai_response.get('error', 'Erro desconhecido') if ai_response else 'Sem resposta'
                result['risk_factors'].append(f"Erro IA: {error_msg}")
                result['risk_score'] = 50
                return result
            
            result['success'] = True
            
            # Processa resposta da IA
            self._process_response(result, ai_response, year)
            
            # Calcula score de risco
            result['risk_score'] = self._calculate_risk_score(result, ai_response)
            
            # Tempo de processamento
            processing_time = int((time.time() - start_time) * 1000)
            
            # Salva an√°lise no banco
            analysis_id = self._save_analysis(
                image_url=image_url,
                year=year,
                model=model,
                result=result,
                ai_response=ai_response,
                processing_time=processing_time
            )
            
            result['analysis_id'] = analysis_id
            
            # Log do resultado
            logger.info(f"‚úì C√≥digo: {result['read_code']}")
            logger.info(f"  Fonte Honda: {'SIM' if result.get('font_is_honda') else 'N√ÉO - SUSPEITO!'}")
            logger.info(f"  Score: {result['risk_score']}")
            logger.info(f"  ID: {analysis_id}")
            
            # Armazena em cache
            self._set_cache(cache_key, result)
            
            return result
            
        except Exception as e:
            logger.error(f"Erro an√°lise: {e}", exc_info=True)
            result['risk_factors'].append(f"Erro: {str(e)}")
            result['risk_score'] = 50
            return result
    
    def _create_empty_result(self, year: int) -> Dict:
        """Cria estrutura de resultado vazia."""
        return {
            'success': False,
            'analysis_id': None,
            'read_code': '',
            'prefix': None,
            'serial': None,
            'expected_model': None,
            'detected_type': 'DESCONHECIDO',
            'expected_type': self.get_expected_type(year),
            'type_match': True,
            'has_mixed_types': False,
            'font_is_honda': True,
            'risk_score': 0,
            'risk_factors': [],
            'font_analysis': {},
            'surface_analysis': {},
            'forensic_enhanced': OPENCV_AVAILABLE,
            'repeated_chars_analysis': [],
            'recommendations': [],
            'references_used': {'fonts': 0}
        }
    # ========================================
    # M√âTODOS DE PROCESSAMENTO DE IMAGEM
    # ========================================
    
    def _apply_forensic_filter(self, image_bytes: bytes) -> Optional[bytes]:
        """
        Aplica filtro forense CLAHE para real√ßar detalhes.
        
        CORRE√á√ÉO v5.16: Adicionado cleanup de mem√≥ria expl√≠cito.
        """
        if not OPENCV_AVAILABLE:
            return None
        
        try:
            with self._image_buffer(image_bytes) as img:
                if img is None:
                    return None
                
                # Converte para LAB
                lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                
                # Aplica CLAHE no canal L
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
                l_enhanced = clahe.apply(l)
                
                # Reconstr√≥i imagem
                lab_enhanced = cv2.merge([l_enhanced, a, b])
                enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)
                
                # Codifica como JPEG
                _, buffer = cv2.imencode('.jpg', enhanced, [cv2.IMWRITE_JPEG_QUALITY, 95])
                
                return buffer.tobytes()
                
        except Exception as e:
            logger.warning(f"Erro no filtro CLAHE: {e}")
            return None
    
    def _upload_analysis_image(self, image_bytes: bytes) -> Optional[str]:
        """
        Faz upload da imagem para storage.
        
        CORRE√á√ÉO v5.16: Thread-safe com lock.
        """
        if not self.supabase:
            return None
        
        try:
            with self._lock:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"analysis_{timestamp}_{hashlib.md5(image_bytes).hexdigest()[:8]}.jpg"
                
                # Upload para storage
                response = self.supabase.storage.from_('motor-images').upload(
                    filename,
                    image_bytes,
                    {'content-type': 'image/jpeg'}
                )
                
                if response:
                    # Retorna URL p√∫blica
                    return self.supabase.storage.from_('motor-images').get_public_url(filename)
                    
        except Exception as e:
            logger.warning(f"Erro no upload: {e}")
        
        return None
    
    # ========================================
    # M√âTODOS DE AN√ÅLISE COM IA
    # ========================================
    
    def _analyze_with_ai_forensic(
        self,
        image_bytes: bytes,
        enhanced_bytes: Optional[bytes],
        year: int
    ) -> Dict:
        """
        An√°lise com IA no modo PERITO FORENSE.
        
        SIMPLIFICADO v5.33: Uma √∫nica chamada com refer√™ncias dos n√∫meros cr√≠ticos.
        """
        try:
            b64_original = base64.b64encode(image_bytes).decode()
            b64_enhanced = base64.b64encode(enhanced_bytes).decode() if enhanced_bytes else None
            expected_type = self.get_expected_type(year)
            
            # Construir prompt com refer√™ncias dos n√∫meros cr√≠ticos (0-9)
            content = self._build_prompt_unico(b64_original, b64_enhanced, expected_type, year)
            
            # Chamada √∫nica √† API
            response = self._call_api_with_retry(content)
            
            if response and response.get('success'):
                return response
            
            return {'success': False, 'error': response.get('error', 'Erro desconhecido')}
            
        except Exception as e:
            logger.error(f"Erro an√°lise IA: {e}")
            return {'success': False, 'error': str(e)}
    
    def _build_prompt_unico(
        self,
        b64_original: str,
        b64_enhanced: Optional[str],
        expected_type: str,
        year: int
    ) -> List[Dict]:
        """
        Prompt √öNICO otimizado para an√°lise PERICIAL.
        
        v5.33: An√°lise como perito forense - detecta evid√™ncias e justifica.
        Score gradual de 0-100 baseado nas evid√™ncias encontradas.
        """
        content = []
        
        system_prompt = self._get_system_prompt()
        
        content.append({
            "type": "text",
            "text": f"""{system_prompt}

# VE√çCULO: Ano {year} | Grava√ß√£o esperada: {expected_type}

---

# üîç REFER√äNCIAS - N√öMEROS HONDA ORIGINAL (0-9)

Voc√™ √© um PERITO FORENSE. Analise cada n√∫mero comparando com as refer√™ncias.
Documente TODAS as evid√™ncias encontradas, mesmo sutis.

**ESCALA DE SCORE:**
- 0-30: Original - caracter√≠sticas consistentes com Honda
- 30-50: Baixo risco - pequenas varia√ß√µes aceit√°veis  
- 50-70: Suspeito - evid√™ncias que merecem aten√ß√£o
- 70-85: Alto risco - m√∫ltiplas evid√™ncias de adultera√ß√£o
- 85-100: Fraude confirmada - evid√™ncias incontest√°veis

## Refer√™ncias:
"""
        })
        
        # Usar cache de fontes (apenas n√∫meros, pr√©-carregados)
        numeros = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
        referencias_enviadas = []
        
        for num in numeros:
            if num in self.font_cache_b64:
                desc = self._get_char_description(num)
                content.append({
                    "type": "text",
                    "text": f"\n**{num}** ({desc}):"
                })
                content.append({
                    "type": "image",
                    "source": {"type": "base64", "media_type": "image/png", "data": self.font_cache_b64[num]}
                })
                referencias_enviadas.append(num)
        
        if referencias_enviadas:
            logger.info(f"  üìö {len(referencias_enviadas)} refer√™ncias (cache): {referencias_enviadas}")
        
        # Imagem do motor
        content.append({
            "type": "text",
            "text": """

---

# üì∑ MOTOR PARA AN√ÅLISE

**PROCEDIMENTO PERICIAL:**

1. **LEITURA:** Identifique cada caractere do c√≥digo
2. **COMPARA√á√ÉO:** Compare cada n√∫mero com a refer√™ncia Honda
3. **EVID√äNCIAS:** Documente diferen√ßas encontradas (formato, propor√ß√£o, estilo)
4. **SUPERF√çCIE:** Verifique marcas de lixa, n√∫meros fantasma, irregularidades
5. **CONCLUS√ÉO:** Score baseado na quantidade e gravidade das evid√™ncias

**INDICADORES DE ADULTERA√á√ÉO:**
- Formato diferente da refer√™ncia Honda
- "1" com altura menor (moral baixa)
- "0" circular fechado (sem aberturas caracter√≠sticas)
- "4" sem gap entre linhas
- "3" com topo reto (poss√≠vel origem do 8)
- "9" similar ao "6" invertido
- Marcas de lixa (riscos paralelos)
- N√∫meros fantasma (grava√ß√£o anterior vis√≠vel)
- Inconsist√™ncia de estilo entre caracteres

## Imagem:
"""
        })
        
        content.append({
            "type": "image",
            "source": {"type": "base64", "media_type": "image/jpeg", "data": b64_original}
        })
        
        # Enhanced
        if b64_enhanced:
            content.append({
                "type": "text",
                "text": "\n## Enhanced (para detectar lixa/fantasmas):"
            })
            content.append({
                "type": "image",
                "source": {"type": "base64", "media_type": "image/jpeg", "data": b64_enhanced}
            })
        
        # Instru√ß√µes de resposta
        content.append({
            "type": "text",
            "text": self._get_response_instructions()
        })
        
        return content
    
    def _get_char_description(self, char: str) -> str:
        """Retorna descri√ß√£o do que verificar em cada caractere."""
        descricoes = {
            '0': "deve ser OVAL com aberturas, N√ÉO c√≠rculo fechado",
            '1': "deve ter ALTURA IGUAL aos outros e serifa no topo",
            '2': "verificar formato do la√ßo inferior",
            '3': "deve ter topo CURVO, n√£o reto",
            '4': "deve ter GAP entre haste e linha horizontal",
            '5': "barriga deve ter abertura √† esquerda",
            '6': "c√≠rculo pode ter leve abertura",
            '7': "N√ÉO deve ter tra√ßo no meio",
            '8': "c√≠rculo superior deve ser MENOR que inferior",
            '9': "deve ter cauda CURVA, n√£o parecer com 6 invertido",
            'A': "verificar formato do tri√¢ngulo",
            'B': "verificar formato das barrigas",
            'C': "verificar abertura",
            'D': "verificar curva",
            'E': "verificar linhas horizontais",
            'F': "verificar linhas horizontais",
            'G': "verificar formato",
            'H': "verificar linhas verticais e horizontal",
            'J': "verificar gancho inferior",
            'K': "verificar diagonais",
            'L': "verificar √¢ngulo",
            'M': "DUAS diagonais formando V",
            'N': "UMA diagonal do topo-esq para base-dir",
            'P': "verificar barriga superior",
            'X': "verificar cruzamento das diagonais"
        }
        return descricoes.get(char, "verificar formato")
    
    def _get_system_prompt(self) -> str:
        """Retorna o system prompt EQUILIBRADO para an√°lise forense."""
        return """# AN√ÅLISE DE MOTOR HONDA - v5.33

## SUA √öNICA TAREFA:
1. Ler o c√≥digo gravado (prefixo + serial)
2. Verificar se h√° EVID√äNCIAS F√çSICAS GRAVES de adultera√ß√£o

## ‚ö†Ô∏è REGRA FUNDAMENTAL:
**ASSUMA QUE O MOTOR √â ORIGINAL.** A maioria dos motores analisados s√£o originais.

## SOBRE MARCAS NA SUPERF√çCIE:
- Motores usados T√äM marcas, riscos e texturas - isso √© NORMAL
- Sujeira, √≥leo, oxida√ß√£o criam padr√µes que parecem "irregulares" - isso √© NORMAL  
- Reflexos de luz podem parecer "riscos paralelos" - isso √© NORMAL
- **VERDADEIRAS marcas de lixa** s√£o: profundas, uniformes, concentradas APENAS na √°rea dos n√∫meros
- Se a "marca" est√° em todo o motor, √© DESGASTE NORMAL, n√£o adultera√ß√£o

## CLASSIFICA√á√ÉO:

**ORIGINAL** (use na maioria dos casos):
- Grava√ß√£o presente e leg√≠vel
- Sem n√∫meros fantasma vis√≠veis
- Sem mistura √≥bvia de laser/estampagem
- Marcas na superf√≠cie = provavelmente uso normal

**SUSPEITO** (use raramente):
- Qualidade de imagem muito ruim para an√°lise
- √Årea dos n√∫meros visivelmente mais polida que o resto

**ADULTERADO** (use APENAS com certeza absoluta):
- N√öMEROS FANTASMA claramente vis√≠veis (vest√≠gios de numera√ß√£o anterior)
- OU mistura √ìBVIA de LASER e ESTAMPAGEM na mesma numera√ß√£o

## ‚ö†Ô∏è N√ÉO USE "ADULTERADO" BASEADO EM:
- Formato dos n√∫meros (0, 1, 4, 6, 8, 9 variam muito)
- "C√≠rculos fechados" - varia√ß√£o normal
- "Marcas de lixa" - quase sempre √© desgaste normal
- Textura irregular - motores usados s√£o assim
- Diferen√ßas de fonte - varia√ß√£o de fabrica√ß√£o"""

    def _get_response_instructions(self) -> str:
        """Retorna instru√ß√µes de formato de resposta - ULTRA SIMPLIFICADA v5.33."""
        return """

# RESPONDA APENAS EM JSON:

```json
{
  "leitura": {
    "linha1": "PREFIXO",
    "linha2": "SERIAL",
    "codigo_completo": "PREFIXO-SERIAL",
    "confianca": 85
  },
  
  "analise_superficie": {
    "numeros_fantasma": false,
    "descricao": "Superf√≠cie com desgaste normal de uso"
  },
  
  "analise_gravacao": {
    "tipo_linha1": "LASER",
    "tipo_linha2": "LASER",
    "mistura_tipos": false
  },
  
  "veredicto": {
    "classificacao": "ORIGINAL",
    "certeza": 85,
    "motivo_principal": "Grava√ß√£o leg√≠vel, sem n√∫meros fantasma ou mistura de tipos"
  }
}
```

## REGRAS DO VEREDICTO:

- **ORIGINAL** (padr√£o): Sem n√∫meros fantasma, sem mistura laser/estampagem
- **SUSPEITO**: Qualidade de imagem impede an√°lise conclusiva  
- **ADULTERADO**: SOMENTE se encontrar N√öMEROS FANTASMA ou MISTURA LASER/ESTAMPAGEM

## ‚ö†Ô∏è CR√çTICO:
- N√ÉO classifique como ADULTERADO por causa de "marcas de lixa" - motores usados t√™m marcas
- N√ÉO classifique como ADULTERADO por causa de formato dos n√∫meros
- NA D√öVIDA, sempre use ORIGINAL"""

    def _call_api_with_retry(self, content: List[Dict], max_retries: int = 2) -> Dict:
        """
        Chama API com retry e backoff exponencial.
        
        NOVO v5.16: Implementa√ß√£o robusta com retry.
        """
        last_error = None
        
        for attempt in range(max_retries + 1):
            try:
                response = httpx.post(
                    "https://api.anthropic.com/v1/messages",
                    headers={
                        "x-api-key": self.api_key,
                        "anthropic-version": "2023-06-01",
                        "content-type": "application/json"
                    },
                    json={
                        "model": "claude-sonnet-4-20250514",
                        "max_tokens": 5000,
                        "messages": [{"role": "user", "content": content}]
                    },
                    timeout=self.API_TIMEOUT
                )
                
                if response.status_code == 200:
                    text = response.json()['content'][0]['text']
                    parsed = self._parse_json_response(text)
                    parsed['success'] = True
                    return parsed
                elif response.status_code == 429:  # Rate limit
                    wait_time = (2 ** attempt) * 5
                    logger.warning(f"Rate limit, aguardando {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    last_error = f"HTTP {response.status_code}: {response.text[:200]}"
                    
            except httpx.TimeoutException:
                last_error = "Timeout na API"
                logger.warning(f"Timeout na tentativa {attempt + 1}")
            except Exception as e:
                last_error = str(e)
                logger.warning(f"Erro na tentativa {attempt + 1}: {e}")
            
            # Backoff exponencial
            if attempt < max_retries:
                time.sleep(2 ** attempt)
        
        return {'success': False, 'error': last_error}
    
    def _parse_json_response(self, text: str) -> Dict:
        """
        Parse robusto da resposta JSON.
        
        CORRE√á√ÉO v5.16: Tratamento de m√∫ltiplos formatos.
        """
        try:
            # Remove marcadores de c√≥digo markdown
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```\s*', '', text)
            text = text.strip()
            
            # Tenta encontrar JSON v√°lido
            match = re.search(r'\{[\s\S]*\}', text)
            if match:
                json_str = match.group()
                
                # Tenta parse direto
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    # Tenta corrigir problemas comuns
                    json_str = re.sub(r',\s*}', '}', json_str)  # Remove v√≠rgulas finais
                    json_str = re.sub(r',\s*]', ']', json_str)
                    return json.loads(json_str)
                    
        except Exception as e:
            logger.warning(f"Erro parse JSON: {e}")
        
        return {}
    # ========================================
    # PROCESSAMENTO DE RESPOSTA
    # ========================================
    
    def _process_response(self, result: Dict, ai: Dict, year: int):
        """
        Processa resposta da IA e atualiza resultado.
        
        CORRE√á√ÉO v5.16: L√≥gica de extra√ß√£o melhorada.
        """
        # LEITURA
        leitura = ai.get('leitura', {})
        l1 = leitura.get('linha1', '').strip()
        l2 = leitura.get('linha2', '').strip()
        code = leitura.get('codigo_completo', '').strip()
        
        # Monta c√≥digo se n√£o veio completo
        if not code and l1 and l2:
            code = f"{l1}-{l2}"
        
        if code:
            # Normaliza c√≥digo
            code = re.sub(r'[^A-Z0-9\-]', '', code.upper())
            result['read_code'] = code
            
            # Extrai prefixo e serial
            parts = code.split('-')
            if parts:
                result['prefix'] = parts[0]
                result['serial'] = parts[1] if len(parts) > 1 else ''
                
                # Busca modelo esperado
                for prefix_candidate in [parts[0], parts[0][:-1], parts[0][:-2]]:
                    if prefix_candidate in self.KNOWN_PREFIXES:
                        result['expected_model'] = self.KNOWN_PREFIXES[prefix_candidate][0]
                        break
        
        result['ocr_confidence'] = {'overall': leitura.get('confianca', 0)}
        
        # AN√ÅLISE DE FONTE
        checklist = ai.get('checklist_fonte', {})
        result['font_analysis'] = checklist
        result['font_is_honda'] = checklist.get('fonte_geral_compativel_honda', True)
        
        # AN√ÅLISE DE GRAVA√á√ÉO
        gravacao = ai.get('analise_gravacao', {})
        tipo_l1 = gravacao.get('tipo_linha1', '').upper()
        tipo_l2 = gravacao.get('tipo_linha2', '').upper()
        
        if tipo_l1 and tipo_l2:
            if tipo_l1 == tipo_l2:
                result['detected_type'] = tipo_l1
            else:
                result['detected_type'] = 'MISTURA'
                result['has_mixed_types'] = True
        
        if gravacao.get('mistura_tipos'):
            result['has_mixed_types'] = True
            result['risk_factors'].append("üö® Mistura de grava√ß√£o (LASER + ESTAMPAGEM)")
        
        if not gravacao.get('compativel_com_ano', True):
            result['type_match'] = False
            result['risk_factors'].append(f"‚ö†Ô∏è Tipo incompat√≠vel com ano {year}")
        
        # AN√ÅLISE DE SUPERF√çCIE
        superficie = ai.get('analise_superficie', {})
        result['surface_analysis'] = superficie
        
        # v5.33: S√≥ adiciona risk_factor para n√∫meros fantasma (evid√™ncia definitiva)
        # Marcas de lixa e textura irregular s√£o ignoradas (IA erra muito)
        if superficie.get('numeros_fantasma'):
            result['risk_factors'].append("üö® N√∫meros fantasma detectados")
        
        # VEREDICTO DA IA
        veredicto = ai.get('veredicto', {})
        classificacao = veredicto.get('classificacao', '').upper()
        certeza = veredicto.get('certeza', 0)
        motivo = veredicto.get('motivo_principal', '')
        motivos = veredicto.get('motivos', [])
        
        # Adiciona motivos √†s recomenda√ß√µes (para refer√™ncia, n√£o como risk_factor)
        for m in motivos[:5]:
            if m:
                result['recommendations'].append(m)
        
        # v5.33: N√ÉO adiciona risk_factors aqui - isso √© feito em _calculate_risk_score
        # de forma filtrada para evitar falsos positivos
    
    # ========================================
    # C√ÅLCULO DE SCORE - ULTRA CONSERVADOR v5.33
    # ========================================
    
    def _calculate_risk_score(self, result: Dict, ai: Dict) -> int:
        """
        Calcula score de risco baseado APENAS em evid√™ncias f√≠sicas GRAVES.
        
        v5.33: Ultra conservador.
        - IGNORA an√°lise de caracteres completamente
        - IGNORA "marcas de lixa" (IA erra muito nisso)
        - S√≥ aumenta score com: n√∫meros fantasma ou mistura laser/estampagem
        """
        
        # =====================================================
        # MARCADOR v5.33 - SE VOC√ä VER ESTE LOG, EST√Å CORRETO!
        # =====================================================
        logger.info("=" * 60)
        logger.info("üî∑ v5.33 ULTRA CONSERVADOR - _calculate_risk_score ATIVO")
        logger.info("=" * 60)
        
        score = 15  # Base baixa - assume original
        
        veredicto = ai.get('veredicto', {})
        classificacao = veredicto.get('classificacao', '').upper()
        certeza = veredicto.get('certeza', 0)
        motivo = veredicto.get('motivo_principal', '')
        
        logger.info(f"  üìã Veredicto IA: {classificacao} ({certeza}%)")
        
        # ==========================================
        # √öNICAS EVID√äNCIAS QUE IMPORTAM
        # ==========================================
        
        superficie = ai.get('analise_superficie', {})
        gravacao = ai.get('analise_gravacao', {})
        
        # N√∫meros fantasma = √öNICA evid√™ncia definitiva de adultera√ß√£o
        if superficie.get('numeros_fantasma'):
            score = 95
            result['risk_factors'].append("üö® N√öMEROS FANTASMA detectados - evid√™ncia de regrava√ß√£o")
            logger.info("  üö® Score 95: N√öMEROS FANTASMA!")
            return score
        
        # Mistura LASER + ESTAMPAGEM = evid√™ncia forte
        if gravacao.get('mistura_tipos'):
            score = 90
            result['risk_factors'].append("üö® MISTURA de grava√ß√£o (LASER + ESTAMPAGEM)")
            logger.info("  üö® Score 90: MISTURA LASER/ESTAMPAGEM!")
            return score
        
        # ==========================================
        # IGNORAR marcas de lixa - IA erra muito
        # ==========================================
        # Comentado porque a IA confunde textura normal com lixa
        # if superficie.get('marcas_lixa') and superficie.get('marcas_paralelas'):
        #     score = 70
        #     result['risk_factors'].append("‚ö†Ô∏è Marcas de lixa paralelas")
        
        # ==========================================
        # VEREDICTO DA IA (muito conservador)
        # ==========================================
        
        if classificacao == 'ORIGINAL':
            score = 15
            result['risk_factors'].append(f"‚úì IA: ORIGINAL ({certeza}%)")
            
        elif classificacao == 'SUSPEITO':
            score = 35
            result['risk_factors'].append(f"‚ö†Ô∏è IA: SUSPEITO ({certeza}%)")
            if motivo:
                result['risk_factors'].append(f"  - {motivo}")
            
        elif classificacao == 'ADULTERADO':
            # S√≥ aceita veredicto ADULTERADO se baseado em evid√™ncias f√≠sicas graves
            motivo_lower = motivo.lower() if motivo else ''
            
            # Veredicto baseado em n√∫meros fantasma ou mistura = aceitar
            if 'fantasma' in motivo_lower or 'mistura' in motivo_lower:
                score = 85
                result['risk_factors'].append(f"üö® IA: ADULTERADO ({certeza}%) - {motivo}")
            else:
                # Qualquer outro motivo (caracteres, lixa, fonte) = IGNORAR
                score = 35
                result['risk_factors'].append(f"‚ö†Ô∏è IA mencionou adultera√ß√£o mas sem evid√™ncia f√≠sica grave")
                logger.info(f"  ‚ÑπÔ∏è Veredicto ADULTERADO ignorado - motivo: {motivo}")
        
        logger.info(f"  üìä Score final: {score}")
        
        return min(score, 100)
    
    def _check_specific_chars(self, checklist: Dict, score: int, fonte_ok: bool) -> Tuple[int, bool]:
        """
        Verifica caracteres espec√≠ficos com crit√©rios de PERITO FORENSE.
        
        Cada indicador contribui para o score de forma independente.
        M√∫ltiplos indicadores se acumulam.
        """
        
        # '4' conectado = forte indicador
        if checklist.get('4_presente'):
            tem_gap = checklist.get('4_tem_gap_visivel', True)
            prob_4 = checklist.get('4_problema', 'nenhum')
            if not tem_gap or prob_4 == 'claramente_conectado':
                score = max(score, 85)
                fonte_ok = False
                logger.info("  üö® Score 85: '4' CONECTADO (sem gap)")
        
        # '1' com MORAL BAIXA ou sem barra
        if checklist.get('1_presente'):
            altura_ok = checklist.get('1_altura_normal', True)
            tem_barra = checklist.get('1_tem_barra_topo', True)
            moral_baixa = checklist.get('1_moral_baixa', False)
            prob_1 = checklist.get('1_problema', 'nenhum')
            
            if moral_baixa or not altura_ok or prob_1 in ['altura_baixa', 'moral_baixa']:
                score = max(score, 80)
                fonte_ok = False
                logger.info("  üö® Score 80: '1' com MORAL BAIXA")
            
            if not tem_barra or prob_1 == 'sem_barra':
                score = max(score, 75)
                fonte_ok = False
                logger.info("  ‚ö†Ô∏è Score 75: '1' SEM BARRA/SERIFA")
        
        # '0' fechado circular (sem aberturas)
        if checklist.get('0_presente'):
            tem_aberturas = checklist.get('0_tem_aberturas', True)
            prob_0 = checklist.get('0_problema', 'nenhum')
            
            if not tem_aberturas or prob_0 == 'fechado_circular':
                score = max(score, 85)
                fonte_ok = False
                logger.info("  üö® Score 85: '0' FECHADO (sem aberturas)")
        
        # '3' com TOPO RETO (provavelmente veio do 8)
        if checklist.get('3_presente'):
            topo_curvo = checklist.get('3_topo_curvo', True)
            topo_reto = checklist.get('3_topo_reto', False)
            prob_3 = checklist.get('3_problema', 'nenhum')
            
            if topo_reto or not topo_curvo or prob_3 in ['topo_reto', 'veio_do_8']:
                score = max(score, 85)
                fonte_ok = False
                logger.info("  üö® Score 85: '3' com TOPO RETO")
        
        # '9' parece '6' invertido
        if checklist.get('9_presente'):
            cauda_curva = checklist.get('9_cauda_curva', True)
            parece_6 = checklist.get('9_parece_6_invertido', False)
            prob_9 = checklist.get('9_problema', 'nenhum')
            
            if parece_6 or prob_9 in ['parece_6', 'cauda_reta', 'circulo_fechado']:
                score = max(score, 85)
                fonte_ok = False
                logger.info(f"  üö® Score 85: '9' {prob_9 or 'parece 6'}")
            elif not cauda_curva:
                score = max(score, 70)
                fonte_ok = False
                logger.info("  ‚ö†Ô∏è Score 70: '9' sem cauda curva")
        
        # '7' europeu
        if checklist.get('7_presente'):
            sem_traco = checklist.get('7_sem_traco_meio', True)
            prob_7 = checklist.get('7_problema', 'nenhum')
            if not sem_traco or prob_7 == 'tem_traco_europeu':
                score = max(score, 80)
                fonte_ok = False
                logger.info("  üö® Score 80: '7' estilo EUROPEU")
        
        # Caracteres secund√°rios
        if checklist.get('5_presente') and not checklist.get('5_barriga_aberta', True):
            score = max(score, 70)
            fonte_ok = False
            logger.info("  ‚ö†Ô∏è Score 70: '5' barriga fechada")
        
        if checklist.get('6_presente') and not checklist.get('6_circulo_aberto', True):
            score = max(score, 70)
            fonte_ok = False
            logger.info("  ‚ö†Ô∏è Score 70: '6' c√≠rculo fechado")
        
        if checklist.get('8_presente') and not checklist.get('8_superior_menor', True):
            score = max(score, 65)
            fonte_ok = False
            logger.info("  ‚ö†Ô∏è Score 65: '8' c√≠rculos iguais")
        
        return score, fonte_ok
    
    def _check_computer_font_pattern(self, checklist: Dict, score: int, fonte_ok: bool) -> Tuple[int, bool]:
        """Detecta padr√£o de fonte de computador."""
        
        padrao_computador = checklist.get('padrao_fonte_computador', False)
        multiplos_fechados = checklist.get('multiplos_circulos_fechados', False)
        
        # Conta c√≠rculos fechados
        circulos_fechados = 0
        if checklist.get('0_problema') == 'fechado_circular':
            circulos_fechados += 1
        if checklist.get('6_problema') == 'circulo_fechado':
            circulos_fechados += 1
        if checklist.get('9_problema') == 'circulo_fechado':
            circulos_fechados += 1
        
        # M√∫ltiplos c√≠rculos fechados = fonte de computador
        if padrao_computador or multiplos_fechados or circulos_fechados >= 2:
            score = max(score, 92)
            fonte_ok = False
            logger.info(f"  üö® Score 92: PADR√ÉO FONTE DE COMPUTADOR ({circulos_fechados} c√≠rculos fechados)")
        
        return score, fonte_ok
        
        return score, fonte_ok
    
    def _count_total_errors(self, checklist: Dict, qtd_erros: int, chars_problema: List) -> int:
        """Conta total de erros encontrados."""
        
        total = max(qtd_erros, len(chars_problema))
        
        if total == 0:
            # Conta manualmente verificando problemas espec√≠ficos
            problem_keys = ['0_problema', '1_problema', '3_problema', '4_problema', 
                           '5_problema', '6_problema', '7_problema', '8_problema', '9_problema']
            for key in problem_keys:
                prob = checklist.get(key, 'nenhum')
                if prob not in ['nenhum', '', None]:
                    total += 1
            
            # Verifica tamb√©m campos booleanos de problemas
            if checklist.get('1_moral_baixa', False):
                total += 1
            if checklist.get('3_topo_reto', False):
                total += 1
            if checklist.get('9_parece_6_invertido', False):
                total += 1
        
        return total
    
    def _check_consistency_and_engraving(
        self,
        ai: Dict,
        checklist: Dict,
        score: int,
        fonte_ok: bool
    ) -> int:
        """
        Verifica consist√™ncia entre linhas, tipo de grava√ß√£o, superf√≠cie e alinhamento.
        
        Crit√©rios de PERITO FORENSE:
        - Mistura de tipos = FRAUDE CONFIRMADA
        - N√∫meros fantasma = FRAUDE CONFIRMADA
        - Marcas de lixa paralelas = FORTE SUSPEITA
        - Desalinhamento severo = SUSPEITA
        - Espa√ßamento irregular = SUSPEITA
        """
        
        gravacao = ai.get('analise_gravacao', {})
        consistencia = checklist.get('consistencia_linha1_linha2', True)
        estilo_consistente = gravacao.get('estilo_fonte_consistente', True)
        
        # Inconsist√™ncia entre linhas = SUSPEITO
        if not consistencia or not estilo_consistente:
            score = max(score, 85)
            logger.info("  üö® Score 85: INCONSIST√äNCIA entre linha 1 e linha 2")
        
        # MISTURA DE TIPOS = FRAUDE CONFIRMADA
        if gravacao.get('mistura_tipos'):
            score = max(score, 98)
            qual_parte = gravacao.get('qual_parte_diferente', '')
            logger.info(f"  üö® Score 98: MISTURA LASER + ESTAMPAGEM {qual_parte}")
        
        # N√öMEROS FANTASMA = FRAUDE CONFIRMADA
        superficie = ai.get('analise_superficie', {})
        checklist_sup = ai.get('checklist_superficie', {})
        
        tem_fantasma = (
            superficie.get('numeros_fantasma', False) or
            checklist_sup.get('numeros_fantasma_visiveis', False)
        )
        if tem_fantasma:
            score = max(score, 98)
            descricao = checklist_sup.get('descricao_fantasma', superficie.get('descricao_detalhada', ''))
            logger.info(f"  üö® Score 98: N√öMEROS FANTASMA {descricao}")
        
        # MARCAS DE LIXA = FORTE SUSPEITA
        tem_lixa = (
            superficie.get('marcas_lixa', False) or
            superficie.get('marcas_paralelas', False) or
            checklist_sup.get('tipo_marcas') == 'lixamento_suspeito' or
            checklist_sup.get('marcas_paralelas_uniformes', False)
        )
        if tem_lixa:
            score = max(score, 75)
            logger.info("  üö® Score 75: MARCAS DE LIXA detectadas")
            
            # Se marcas est√£o concentradas nos n√∫meros = mais suspeito
            if checklist_sup.get('marcas_concentradas_nos_numeros', False):
                score = max(score, 85)
                logger.info("  üö® Score 85: Lixa concentrada nos n√∫meros!")
        
        # DESALINHAMENTO
        checklist_alin = ai.get('checklist_alinhamento', {})
        
        # Desalinhamento severo ou pun√ß√£o manual = FORTE SUSPEITA
        if checklist_alin.get('desalinhamento_severo', False) or checklist_alin.get('indica_puncao_manual', False):
            score = max(score, 80)
            qual = checklist_alin.get('qual_caractere_desalinhado', '')
            logger.info(f"  üö® Score 80: DESALINHAMENTO SEVERO / PUN√á√ÉO MANUAL {qual}")
        elif not checklist.get('numeros_alinhados', True) or not checklist_alin.get('todos_na_mesma_linha_base', True):
            score = max(score, 70)
            logger.info("  ‚ö†Ô∏è Score 70: Desalinhamento detectado")
        
        # ESPA√áAMENTO IRREGULAR = SUSPEITA
        espacamento_irregular = (
            checklist_alin.get('espacamento_irregular', False) or
            not checklist.get('espa√ßamento_uniforme', True)
        )
        if espacamento_irregular:
            score = max(score, 75)
            qual = checklist_alin.get('qual_espacamento_irregular', '')
            logger.info(f"  ‚ö†Ô∏è Score 75: ESPA√áAMENTO IRREGULAR {qual}")
        
        return score
    
    def _apply_ai_verdict(
        self,
        ai: Dict,
        checklist: Dict,
        score: int,
        fonte_ok: bool,
        qtd_erros: int,
        chars_problema: List
    ) -> int:
        """
        DUPLA CHECAGEM: Aplica veredicto da IA comparando com an√°lise estruturada.
        
        Esta √© a segunda camada de verifica√ß√£o. O veredicto da IA serve para:
        1. Confirmar problemas detectados no checklist
        2. Detectar problemas que o checklist n√£o capturou
        3. Identificar inconsist√™ncias que requerem aten√ß√£o
        """
        
        veredicto = ai.get('veredicto', {})
        classificacao = veredicto.get('classificacao', '').upper()
        certeza = veredicto.get('certeza', 0)
        motivos = veredicto.get('motivos', [])
        
        if classificacao == 'ADULTERADO':
            # IA detectou adultera√ß√£o
            if not fonte_ok or qtd_erros > 0 or len(chars_problema) > 0:
                # CONFIRMADO: Checklist tamb√©m indica problemas
                score = max(score, int(certeza * 0.95))
                logger.info(f"  ‚úì DUPLA CONFIRMA√á√ÉO: IA e Checklist concordam - ADULTERADO ({certeza}%)")
            else:
                # IA viu algo que o checklist n√£o capturou
                # Confia na IA mas com peso menor
                score = max(score, int(certeza * 0.7))
                logger.info(f"  ‚ÑπÔ∏è IA detectou adultera√ß√£o n√£o capturada no checklist: {motivos}")
                
        elif classificacao == 'SUSPEITO':
            # IA tem d√∫vidas
            if score < 50:
                # Checklist n√£o encontrou nada mas IA est√° em d√∫vida
                score = max(score, int(certeza * 0.5))
                logger.info(f"  ‚ÑπÔ∏è IA est√° em d√∫vida ({certeza}%): {motivos}")
            else:
                # Checklist j√° indicou problemas, IA confirma suspeita
                score = max(score, int(certeza * 0.7))
                logger.info(f"  ‚ö†Ô∏è IA confirma suspeita do checklist ({certeza}%)")
            
        elif classificacao == 'ORIGINAL':
            # IA diz que √© original
            
            # VERIFICA√á√ÉO EXTRA: Checar indicadores de superf√≠cie
            checklist_sup = ai.get('checklist_superficie', {})
            superficie = ai.get('analise_superficie', {})
            checklist_alin = ai.get('checklist_alinhamento', {})
            
            # Indicadores graves que a IA pode ter subestimado
            tem_fantasma = (
                checklist_sup.get('numeros_fantasma_visiveis', False) or
                superficie.get('numeros_fantasma', False)
            )
            tem_lixa = (
                checklist_sup.get('tipo_marcas') == 'lixamento_suspeito' or
                superficie.get('marcas_lixa', False)
            )
            desalinhamento_severo = checklist_alin.get('desalinhamento_severo', False)
            puncao_manual = checklist_alin.get('indica_puncao_manual', False)
            
            # Se h√° indicadores graves, N√ÉO aceitar o veredicto ORIGINAL
            if tem_fantasma:
                score = max(score, 90)
                logger.info("  üö® OVERRIDE: N√∫meros fantasma detectados - ignorando veredicto ORIGINAL")
            elif tem_lixa:
                score = max(score, 75)
                logger.info("  ‚ö†Ô∏è OVERRIDE: Marcas de lixa - ignorando veredicto ORIGINAL")
            elif desalinhamento_severo or puncao_manual:
                score = max(score, 80)
                logger.info("  ‚ö†Ô∏è OVERRIDE: Desalinhamento severo - ignorando veredicto ORIGINAL")
            elif score >= 70:
                # Checklist j√° indicou score alto, manter
                logger.info(f"  ‚ö†Ô∏è Checklist indica score {score}, IA diz ORIGINAL - mantendo score do checklist")
            elif score >= 50:
                # Score m√©dio - reduzir levemente mas manter suspeita
                score = int(score * 0.9)
                logger.info(f"  ‚ÑπÔ∏è IA diz ORIGINAL mas h√° suspeitas - score ajustado para {score}")
            else:
                # Checklist OK e IA OK = provavelmente original
                logger.info("  ‚úì DUPLA CONFIRMA√á√ÉO: IA e Checklist concordam - ORIGINAL")
        
        return score
        
        return score
    
    # ========================================
    # M√âTODOS DE PERSIST√äNCIA
    # ========================================
    
    def _save_analysis(
        self,
        image_url: Optional[str],
        year: int,
        model: Optional[str],
        result: Dict,
        ai_response: Dict,
        processing_time: int
    ) -> Optional[str]:
        """Salva an√°lise no banco de dados."""
        if not self.supabase:
            return None
        
        try:
            data = {
                'image_url': image_url,
                'year_informed': year,
                'model_informed': model,
                'read_code': result.get('read_code'),
                'prefix': result.get('prefix'),
                'serial': result.get('serial'),
                'detected_type': result.get('detected_type'),
                'expected_type': result.get('expected_type'),
                'risk_score': result.get('risk_score'),
                'verdict': self.get_verdict(result.get('risk_score', 0)),
                'has_mixed_types': result.get('has_mixed_types', False),
                'risk_factors': result.get('risk_factors', []),
                'ai_response': ai_response,
                'processing_time_ms': processing_time,
                'created_at': datetime.utcnow().isoformat()
            }
            
            response = self.supabase.table('analysis_history').insert(data).execute()
            
            if response.data:
                return response.data[0].get('id')
                
        except Exception as e:
            logger.error(f"Erro salvando an√°lise: {e}")
        
        return None
